{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\fftpack\\basic.py:160: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  z[index] = x\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingData\\anger (100).wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\signal\\signaltools.py:491: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return x[reverse].conj()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\signal\\signaltools.py:251: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  in1zpadded[sc] = in1.copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingData\\anger (101).wav\n",
      "trainingData\\anger (102).wav\n",
      "trainingData\\anger (103).wav\n",
      "trainingData\\anger (104).wav\n",
      "trainingData\\anger (105).wav\n",
      "trainingData\\anger (106).wav\n",
      "trainingData\\anger (107).wav\n",
      "trainingData\\anger (108).wav\n",
      "trainingData\\anger (109).wav\n",
      "trainingData\\anger (110).wav\n",
      "trainingData\\anger (111).wav\n",
      "trainingData\\anger (112).wav\n",
      "trainingData\\anger (113).wav\n",
      "trainingData\\anger (114).wav\n",
      "trainingData\\anger (115).wav\n",
      "trainingData\\anger (116).wav\n",
      "trainingData\\anger (117).wav\n",
      "trainingData\\anger (118).wav\n",
      "trainingData\\anger (119).wav\n",
      "trainingData\\anger (120).wav\n",
      "trainingData\\anger (121).wav\n",
      "trainingData\\anger (122).wav\n",
      "trainingData\\anger (123).wav\n",
      "trainingData\\anger (124).wav\n",
      "trainingData\\anger (21).wav\n",
      "trainingData\\anger (22).wav\n",
      "trainingData\\anger (23).wav\n",
      "trainingData\\anger (24).wav\n",
      "trainingData\\anger (25).wav\n",
      "trainingData\\anger (26).wav\n",
      "trainingData\\anger (27).wav\n",
      "trainingData\\anger (28).wav\n",
      "trainingData\\anger (29).wav\n",
      "trainingData\\anger (30).wav\n",
      "trainingData\\anger (31).wav\n",
      "trainingData\\anger (32).wav\n",
      "trainingData\\anger (33).wav\n",
      "trainingData\\anger (34).wav\n",
      "trainingData\\anger (35).wav\n",
      "trainingData\\anger (36).wav\n",
      "trainingData\\anger (37).wav\n",
      "trainingData\\anger (38).wav\n",
      "trainingData\\anger (39).wav\n",
      "trainingData\\anger (40).wav\n",
      "trainingData\\anger (41).wav\n",
      "trainingData\\anger (42).wav\n",
      "trainingData\\anger (43).wav\n",
      "trainingData\\anger (44).wav\n",
      "trainingData\\anger (45).wav\n",
      "trainingData\\anger (46).wav\n",
      "trainingData\\anger (47).wav\n",
      "trainingData\\anger (48).wav\n",
      "trainingData\\anger (49).wav\n",
      "trainingData\\anger (50).wav\n",
      "trainingData\\anger (51).wav\n",
      "trainingData\\anger (52).wav\n",
      "trainingData\\anger (53).wav\n",
      "trainingData\\anger (54).wav\n",
      "trainingData\\anger (55).wav\n",
      "trainingData\\anger (56).wav\n",
      "trainingData\\anger (57).wav\n",
      "trainingData\\anger (58).wav\n",
      "trainingData\\anger (59).wav\n",
      "trainingData\\anger (60).wav\n",
      "trainingData\\anger (61).wav\n",
      "trainingData\\anger (62).wav\n",
      "trainingData\\anger (63).wav\n",
      "trainingData\\anger (64).wav\n",
      "trainingData\\anger (65).wav\n",
      "trainingData\\anger (66).wav\n",
      "trainingData\\anger (67).wav\n",
      "trainingData\\anger (68).wav\n",
      "trainingData\\anger (69).wav\n",
      "trainingData\\anger (70).wav\n",
      "trainingData\\anger (71).wav\n",
      "trainingData\\anger (72).wav\n",
      "trainingData\\anger (73).wav\n",
      "trainingData\\anger (74).wav\n",
      "trainingData\\anger (75).wav\n",
      "trainingData\\anger (76).wav\n",
      "trainingData\\anger (77).wav\n",
      "trainingData\\anger (78).wav\n",
      "trainingData\\anger (79).wav\n",
      "trainingData\\anger (80).wav\n",
      "trainingData\\anger (81).wav\n",
      "trainingData\\anger (82).wav\n",
      "trainingData\\anger (83).wav\n",
      "trainingData\\anger (84).wav\n",
      "trainingData\\anger (85).wav\n",
      "trainingData\\anger (86).wav\n",
      "trainingData\\anger (87).wav\n",
      "trainingData\\anger (88).wav\n",
      "trainingData\\anger (89).wav\n",
      "trainingData\\anger (90).wav\n",
      "trainingData\\anger (91).wav\n",
      "trainingData\\anger (92).wav\n",
      "trainingData\\anger (93).wav\n",
      "trainingData\\anger (94).wav\n",
      "trainingData\\anger (95).wav\n",
      "trainingData\\anger (96).wav\n",
      "trainingData\\anger (97).wav\n",
      "trainingData\\anger (98).wav\n",
      "trainingData\\anger (99).wav\n",
      "trainingData\\happy (16).wav\n",
      "trainingData\\happy (17).wav\n",
      "trainingData\\happy (18).wav\n",
      "trainingData\\happy (19).wav\n",
      "trainingData\\happy (20).wav\n",
      "trainingData\\happy (21).wav\n",
      "trainingData\\happy (22).wav\n",
      "trainingData\\happy (23).wav\n",
      "trainingData\\happy (24).wav\n",
      "trainingData\\happy (25).wav\n",
      "trainingData\\happy (26).wav\n",
      "trainingData\\happy (27).wav\n",
      "trainingData\\happy (28).wav\n",
      "trainingData\\happy (29).wav\n",
      "trainingData\\happy (30).wav\n",
      "trainingData\\happy (31).wav\n",
      "trainingData\\happy (32).wav\n",
      "trainingData\\happy (33).wav\n",
      "trainingData\\happy (34).wav\n",
      "trainingData\\happy (35).wav\n",
      "trainingData\\happy (36).wav\n",
      "trainingData\\happy (37).wav\n",
      "trainingData\\happy (38).wav\n",
      "trainingData\\happy (39).wav\n",
      "trainingData\\happy (40).wav\n",
      "trainingData\\happy (41).wav\n",
      "trainingData\\happy (42).wav\n",
      "trainingData\\happy (43).wav\n",
      "trainingData\\happy (44).wav\n",
      "trainingData\\happy (45).wav\n",
      "trainingData\\happy (46).wav\n",
      "trainingData\\happy (47).wav\n",
      "trainingData\\happy (48).wav\n",
      "trainingData\\happy (49).wav\n",
      "trainingData\\happy (50).wav\n",
      "trainingData\\happy (51).wav\n",
      "trainingData\\happy (52).wav\n",
      "trainingData\\happy (53).wav\n",
      "trainingData\\happy (54).wav\n",
      "trainingData\\happy (55).wav\n",
      "trainingData\\happy (56).wav\n",
      "trainingData\\happy (57).wav\n",
      "trainingData\\happy (58).wav\n",
      "trainingData\\happy (59).wav\n",
      "trainingData\\happy (60).wav\n",
      "trainingData\\happy (61).wav\n",
      "trainingData\\happy (62).wav\n",
      "trainingData\\happy (63).wav\n",
      "trainingData\\happy (64).wav\n",
      "trainingData\\happy (65).wav\n",
      "trainingData\\happy (66).wav\n",
      "trainingData\\sad (16).wav\n",
      "trainingData\\sad (17).wav\n",
      "trainingData\\sad (18).wav\n",
      "trainingData\\sad (19).wav\n",
      "trainingData\\sad (20).wav\n",
      "trainingData\\sad (21).wav\n",
      "trainingData\\sad (22).wav\n",
      "trainingData\\sad (23).wav\n",
      "trainingData\\sad (24).wav\n",
      "trainingData\\sad (25).wav\n",
      "trainingData\\sad (26).wav\n",
      "trainingData\\sad (27).wav\n",
      "trainingData\\sad (28).wav\n",
      "trainingData\\sad (29).wav\n",
      "trainingData\\sad (30).wav\n",
      "trainingData\\sad (31).wav\n",
      "trainingData\\sad (32).wav\n",
      "trainingData\\sad (33).wav\n",
      "trainingData\\sad (34).wav\n",
      "trainingData\\sad (35).wav\n",
      "trainingData\\sad (36).wav\n",
      "trainingData\\sad (37).wav\n",
      "trainingData\\sad (38).wav\n",
      "trainingData\\sad (39).wav\n",
      "trainingData\\sad (40).wav\n",
      "trainingData\\sad (41).wav\n",
      "trainingData\\sad (42).wav\n",
      "trainingData\\sad (43).wav\n",
      "trainingData\\sad (44).wav\n",
      "trainingData\\sad (45).wav\n",
      "trainingData\\sad (46).wav\n",
      "trainingData\\sad (47).wav\n",
      "trainingData\\sad (48).wav\n",
      "trainingData\\sad (49).wav\n",
      "trainingData\\sad (50).wav\n",
      "trainingData\\sad (51).wav\n",
      "trainingData\\sad (52).wav\n",
      "trainingData\\sad (53).wav\n",
      "trainingData\\sad (54).wav\n",
      "trainingData\\sad (55).wav\n",
      "trainingData\\sad (56).wav\n",
      "trainingData\\sad (57).wav\n",
      "trainingData\\sad (58).wav\n",
      "trainingData\\sad (59).wav\n",
      "trainingData\\sad (60).wav\n",
      "trainingData\\sad (61).wav\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "'''\n",
    "    function: extract_features\n",
    "    input: path to mp3 files\n",
    "    output: csv file containing features extracted\n",
    "\n",
    "    This function reads the content in a directory and for each mp3 file detected\n",
    "    reads the file and extracts relevant features using librosa library for audio\n",
    "    signal processing\n",
    "'''\n",
    "\n",
    "\n",
    "def extract_feature(path):\n",
    "    id = 1  # Song ID\n",
    "    feature_set = pd.DataFrame()  # Feature Matrix\n",
    "\n",
    "    # Individual Feature Vectors\n",
    "    tempo_vector = pd.Series()\n",
    "    average_beats = pd.Series()\n",
    "    chroma_stft_mean = pd.Series()\n",
    "    chroma_cq_mean = pd.Series()\n",
    "    chroma_cens_mean = pd.Series()\n",
    "    mel_mean = pd.Series()\n",
    "    mfcc_mean = pd.Series()\n",
    "    mfcc_delta_mean = pd.Series()\n",
    "    rmse_value = pd.Series()\n",
    "    energy_value=pd.Series()\n",
    "    pow_value=pd.Series()\n",
    "\n",
    "    # Traversing over each file in path\n",
    "    file_data = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    for line in file_data:\n",
    "        if (line[-1:] == '\\n'):\n",
    "            line = line[:-1]\n",
    "\n",
    "        # Reading Song\n",
    "        audio = path + line\n",
    "        y, sr = librosa.load(audio, duration=5)\n",
    "        S = np.abs(librosa.stft(y))\n",
    "\n",
    "        # Extracting Features\n",
    "        tempo, beats = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        chroma_cq = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "        chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr)\n",
    "        melspectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        rmse = librosa.feature.rmse(y=y)\n",
    "        energy = librosa.feature.melspectrogram(y=y, sr=sr, power=1)\n",
    "        power = librosa.feature.melspectrogram(y=y, sr=sr, power=2)\n",
    "        energy=librosa.core.amplitude_to_db (energy)\n",
    "        power=librosa.core.power_to_db (power)\n",
    "\n",
    "        # Transforming Features\n",
    "        tempo_vector.set_value(id, tempo)  # tempo\n",
    "        average_beats.set_value(id, np.average(beats))\n",
    "        chroma_stft_mean.set_value(id, np.mean(chroma_stft))  # chroma stft\n",
    "        chroma_cq_mean.set_value(id, np.mean(chroma_cq))  # chroma cq\n",
    "        chroma_cens_mean.set_value(id, np.mean(chroma_cens))  # chroma cens\n",
    "        mel_mean.set_value(id, np.mean(melspectrogram))  # melspectrogram\n",
    "        mfcc_mean.set_value(id, np.mean(mfcc))  # mfcc\n",
    "        mfcc_delta_mean.set_value(id, np.mean(mfcc_delta))  # mfcc delta\n",
    "        rmse_value.set_value(id,np.mean(rmse))\n",
    "        energy_value.set_value(id,np.mean(energy))\n",
    "        pow_value.set_value(id,np.mean(power))\n",
    "        print(audio)\n",
    "        id = id + 1\n",
    "\n",
    "    # Concatenating Features into one csv and json format\n",
    "    feature_set['tempo'] = tempo_vector  # tempo\n",
    "    feature_set['average_beats'] = average_beats\n",
    "    feature_set['chroma_stft_mean'] = chroma_stft_mean  # chroma stft\n",
    "    feature_set['chroma_cq_mean'] = chroma_cq_mean  # chroma cq\n",
    "    feature_set['chroma_cens_mean'] = chroma_cens_mean  # chroma cens\n",
    "    feature_set['melspectrogram_mean'] = mel_mean  # melspectrogram\n",
    "    feature_set['mfcc_mean'] = mfcc_mean  # mfcc\n",
    "    feature_set['mfcc_delta_mean'] = mfcc_delta_mean  # mfcc delta\n",
    "    feature_set['rmse_value'] = rmse_value  # rmse\n",
    "    feature_set['energy_value'] = energy_value  # rmse\n",
    "    feature_set['pow_value'] = pow_value # rmse\n",
    "\n",
    "\n",
    "    # Converting Dataframe into CSV Excel and JSON file\n",
    "    feature_set.to_csv('features.csv')\n",
    "    #feature_set.to_json('Emotion_features.json')\n",
    "\n",
    "\n",
    "# Extracting Feature Function Call\n",
    "extract_feature('trainingData\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
